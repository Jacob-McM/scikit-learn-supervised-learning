{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85e34a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d803bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Import\n",
    "lend_data = pd.read_csv('Resources/lending_data.csv')\n",
    "lend_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36295b68",
   "metadata": {},
   "source": [
    "## Pre-Model thoughts and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229afc7",
   "metadata": {},
   "source": [
    "I believe that the Random Forest Classifier will outperform the Logistic Regression model *if* I model the data to properly suit either model's strengths. To expand, I believe that the Logistic Regression model is more likely to perform better if I do not create well thought out models. From my reading and understanding, Logistic Regression models suffer from overfitting which could lead to reliability risk in the predictive ability of the model. Logistic Regression models also suffer from limited scope in their dimensional analysis, something that a Random Forest Classifier does not have issues with. With my limited understanding of credit risk evaluation, I would think that the kind of analysis to most accurately provide an answer of whether or not someone is lended money would be multidimensional. I also believe that you are not always going to be able to have access to the information that would make a Random Forest Classifier outperform the Logistic Regression Model. \n",
    "\n",
    "With that said, I've been excessively safe about my decision, giving plenty of conditions for either models performance. For the sake of this assignment, I will say I think for this dataset the Logistic Regression Model will outperform the Random Forest Classifier. My primary reasoning is that all the data is numeric, which from my reading supports the success/efficacy of the Logistic Regression model. My secondary reasoning is that I believe with my ability, I am more likely to have success using the Logistic Regression Model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42873cd",
   "metadata": {},
   "source": [
    "## Training and Fitting Logistical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "4cc83563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lend_data['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "453ebddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77536, 7) (77536,)\n"
     ]
    }
   ],
   "source": [
    "## X_train, X_Test, y_train, y_test\n",
    "\n",
    "## Independant input variables\n",
    "X = lend_data.drop('loan_status', axis=1)\n",
    "\n",
    "## Outcome dependant variable\n",
    "y = lend_data['loan_status']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c5fe15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f3d32001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.91      0.88       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n",
      "0.9921240885954051\n",
      "0.9918489475856377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "targets = [\"0\", \"1\"]\n",
    "log_model =  LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "prediction =  log_model.predict(X_test)\n",
    "print(classification_report(y_test, prediction, target_names=targets ))\n",
    "print(log_model.score(X_train, y_train))\n",
    "print(log_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "7a26ff17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45639</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51614</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19384 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictions  actual\n",
       "60914            0       0\n",
       "36843            0       0\n",
       "1966             0       0\n",
       "70137            0       0\n",
       "27237            0       0\n",
       "...            ...     ...\n",
       "45639            0       0\n",
       "11301            0       0\n",
       "51614            0       0\n",
       "4598             0       0\n",
       "2793             0       0\n",
       "\n",
       "[19384 rows x 2 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A dataframe visualization of the predicted loan status vs actual loan status.\n",
    "\n",
    "pd.DataFrame({\"predictions\": prediction, \"actual\":y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c17f3",
   "metadata": {},
   "source": [
    "Well, if I did not have a reference value for what is to be expected, I would have spent far more time trying to find out if the 99% accuracy was a cause for concern. The reference for this says `0.9908171687990095` and my result is `0.9918489475856377`. Either way, the 99% accuracy, if I am interpreting correctly, means that the trained model was able to predict if a loan status should be a 0 or 1 with that 99% accuracy based on the independent input variables I passed to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d62b9",
   "metadata": {},
   "source": [
    "## Training and Fitting Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd8abdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  lend_data.drop('loan_status', axis=1)\n",
    "y = lend_data['loan_status']\n",
    "targets = [\"0\", \"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7c48bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6cda8ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.89      0.87       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.94      0.93     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n",
      "Trained: 0.9975409272252029\n",
      "Test: 0.9914878250103177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "trees = RandomForestClassifier(random_state=1).fit(X_train, y_train)\n",
    "prediction =  trees.predict(X_test)\n",
    "print(classification_report(y_test, prediction, target_names=targets ))\n",
    "print(f\"Trained: {trees.score(X_train, y_train)}\")\n",
    "print(f\"Test: {trees.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22acec3d",
   "metadata": {},
   "source": [
    "The trained accuracy is really strong. The test accuracy is also strong. As explained above, I would be skeptical if I was not given reference values. The reference value for this model is `0.9910751134956666`, which is not too terribly far away, as far as I know, from a value I received, `0.9914878250103177`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87df21",
   "metadata": {},
   "source": [
    "## Conclusions/ Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aacb35f",
   "metadata": {},
   "source": [
    "Both models performed well, performing just as well as each other. The Logistic Regression model returned an accuracy for me that generally falls around `0.991848` and so on. The Random Forest Classifier model returned an accuracy for me that generally falls around `0.991487` and so on. The accuracy difference between these is `0.00036`. At this point, I still consider myself a layman-in-learning about machine learning. At this point, justifying a difference between either result feels like splitting hairs. My prediction is numerically correct in that the Logistic Regression model provided a higher score. To me, my prediction feels like a wash, and either model can be used on this data to provide insight into what loan status the parameters provided deserve.\n",
    "\n",
    "Why did they perform nearly the same? Ignoring any potential user error, the discussion could be about the dataset. The dataset, from my understanding/interpretation is linearly separable, and is not complicated by the need for multidimensional analysis, nullifying an advantage Random Forest might have.\n",
    "\n",
    "Ultimately, I would say based on this, this dataset can be interpreted and trained on either model to produce a well trained result, as either model must be well suited to the parameters of the dataset. To me, that means that the markers that determine a 0 or 1 for a given loan status are consistent and well based on the parameters in this dataset. If I had to say, the dataset does have a lot of information that lends itself to establishing a good basis for predictability, even just for a human. Loan size, Debt:Income, and derogatory marks seem like strong rules of thumb for lending practices. If my understanding is correct, these are also relative parameters that are factors in one's credit score, which from my knowledge, a credit score can be a deciding factor in a borrower receiving consideration for a loan. \n",
    "\n",
    "So, my conclusion would be that both models are suitable for this dataset, and both perform well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
